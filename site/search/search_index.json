{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"AfriSenti-SemEval Shared Task 12 AfriSenti-SemEval: Sentiment Analysis for African Languages Part of the 17th International Workshop on Semantic Evaluation Please use the following BibTex entry to cite us if you use our dataset: SemEval-2023 Task 12: Sentiment Analysis for African Languages (AfriSenti-SemEval) . @inproceedings {muhammadSemEval2023, title = {{SemEval-2023 Task 12: Sentiment Analysis for African Languages (AfriSenti-SemEval)}}, author = {Shamsuddeen Hassan Muhammad and Idris Abdulmumin and Seid Muhie Yimam and David Ifeoluwa Adelani and Ibrahim Sa'id Ahmad and Nedjma Ousidhoum and Abinew Ali Ayele and Saif M. Mohammad and Meriem Beloucif and Sebastian Ruder}, booktitle = {Proceedings of the 17th {{International Workshop}} on {{Semantic Evaluation}} ({{SemEval-2023}})}, publisher = {{Association for Computational Linguistics}}, year = {2023}, url = {https://arxiv.org/pdf/2304.06845.pdf} } AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages . @misc {muhammad2023afrisenti, title={{AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages}}, author={Shamsuddeen Hassan Muhammad and Idris Abdulmumin and Abinew Ali Ayele and Nedjma Ousidhoum and David Ifeoluwa Adelani and Seid Muhie Yimam and Ibrahim Sa'id Ahmad and Meriem Beloucif and Saif M. Mohammad and Sebastian Ruder and Oumaima Hourrane and Pavel Brazdil and Felermino D\u00e1rio M\u00e1rio Ant\u00f3nio Ali and Davis David and Salomey Osei and Bello Shehu Bello and Falalu Ibrahim and Tajuddeen Gwadabe and Samuel Rutunda and Tadesse Belay and Wendimu Baye Messelle and Hailu Beshada Balcha and Sisay Adugna Chala and Hagos Tesfahun Gebremichael and Bernard Opoku and Steven Arthur}, year={2023}, doi={10.48550/arXiv.2302.08956}, url={https://arxiv.org/pdf/2302.08956.pdf} } Contact organizers at: afrisenti-semeval-organizers@googlegroups.com Visit CodaLab competition website AfriSenti dataset is available at task's: GitHub repo Motivation Due to the widespread use of the Internet and social media platforms, most languages are becoming digitally available. This allows for various artificial intelligence (AI) applications that enable tasks such as sentiment analysis, machine translation and hateful content detection. According to UNESCO (2003), 30% of all living languages, around 2,058, are African languages. However, most of these languages do not have curated datasets for developing such AI applications. Recently, various individual and funded initiatives, such as the Lacuna Fund, have set out to reverse this trend and create such datasets for African languages. However, research is required to determine both the suitability of current natural language processing (NLP) techniques and the development of novel techniques to maximize the applications of such datasets. There has been a growing interest in sentiment analysis which applies to many domains, including public health, commerce/business, art and literature, social sciences, neuroscience, and psychology ( Mohammad, Saif M, 2022 ). Previous shared tasks on sentiment analysis include Mohammad, Saif M et al., (2018), Nakov et al., (2016), Pontiki et al., Ghosh et al., (2015), (2014), and so on . However, none of these tasks included African languages. Though Mohammad, Saif, et al. (2018) included standard Arabic, we focus on Arabic dialects from African countries: Algerian Arabic and Tunisian Arabizi . We believe SemEval is the right venue, due to its popularity and widespread acceptance, to carry out shared tasks for African languages to strengthen their further development. In this shared task, we have covered 17 African languages, Hausa , Yoruba , Igbo , Nigerian Pidgin from Nigeria, Amharic , Tigrinya , and Oromo from Ethiopia, Swahili from Kenya and Tanzania, Algerian Arabic dialect from Algeria, Kinyarwanda from Rwanda, Twi from Ghana, Mozambique Portuguese from Mozambique and Moroccan Arabic/Darija from Morocco. Task Overview The AfriSenti-SemEval Shared Task 12 is based on a collection of Twitter datasets in 14 African languages for sentiment classification. It consists of three sub-tasks. Participants can select one or more sub-tasks depending on their preference. In each sub-task also, the participant may wish to participate in any number of languages as so wished. Task A: Monolingual Sentiment Classification Given training data in a target language, determine the polarity of a tweet in the target language (positive, negative, or neutral). If a tweet conveys both a positive and negative sentiment, whichever is the stronger sentiment should be chosen. This sub-task has 15 tracks: Note: You are free to select one or more tracks in this sub-task. Track 1: Hausa Track 2: Yoruba Track 3: Igbo Track 4: Nigerian_Pidgin Track 5: Amharic Track 6: Algerian Arabic Track 7: Moroccan Arabic/Darija, Track 8: Swahili Track 9: Kinyarwanda Track 10: Twi Track 11: Mozambican Portuguese Track 12: Xitsonga ( Mozambique Dialect ) Track 13: Setswana (data to be released soon) Track 14: isiZulu (data to be released soon) Track 15: Xitsonga (South-African Dialect, to be released soon) Note: Tweets in each language are code-mix. Read our NaijaSenti paper for more information. Task B: Multilingual Sentiment Classification Given combined training data from Task-A (Track 1 to 12), determine the polarity of a tweet in the target language (positive, negative, or neutral). This sub-task has only one track with 12 languages (Hausa, Yoruba, Igbo, Nigerian_Pidgin, Amharic, Algerian Arabic, Moroccan Arabic/Darija, Swahili, Kinyarwanda, Twi, Mozambican Portuguese, and Xitsonga( Mozambique Dialect )): Track 16: 12 languages in Task A Task C: Zero-Shot Sentiment Classification Given unlabelled tweets in two African languages (Tigrinya and Oromo), leverage any or all of the available training datasets (in Task:A ) to determine the sentiment of a tweet in the two target languages. This task has two (2) tracks. Note: You are free to select one or more tracks in this sub-task. Track 17: Zero-Shot on Tigrinya Track 18: Zero-Shot on Oromo Dataset Examples The dataset involves tweets labeled with three sentiment classes (positive, negative, neutral) in 14 African languages. Each tweet is annotated by three annotators following the annotation guidelines in ( Mohammad, Saif M, 2016 ). We use a form of majority vote to determine the sentiment of the tweet. See more in our paper ( Muhammad et al., 2022 , Yimam et al., 2020 ). Below is a sample dataset for the 4 Nigerian languges (Muhammad et al., 2022): The datasets are available via the CodaLab competition website Starter kit We provide a Starter Ki t on our GitHub Repo that can be used to crearte a baseline system. Why Participate ? Promote NLP research involving African languages, Opportunity to write a system-description paper that describes their system, resources used, results, and analysis. Stand a chance to win an award. Opportunity to network with renowned experts in the AI and NLP community. Resources on Paper Submission Paper Submission Requirements Guidelines for Writing Papers Paper Style Files Paper Submission Site Important Dates Descriptions Deadlines Sample Data Ready 15 July 2022 Training Data Ready 11 September 2022 Evaluation Start 10 January 2023 Evaluation End 31 January 2023 System Description Paper Due 28th February 2023 Notification to authors 31 March 2023 Camera ready due 21 April 2023 SemEval workshop 2023 13-14 July 2023 (co-located with ACL-2023 in Toronto, Canada All deadlines are 23:59 UTC-12 (\"anywhere on Earth\"). Communication Join Task Mailing List Join Task Slack Channel to communicate with the organizers. Contact Organizers: afrisenti-semeval-organizers@googlegroups.com Previous Shared Tasks Shared tasks in English: SemEval-2017 , SemEval-2016 , SemEval-2015 , SemEval-2014 , SemEval-2013 Shared tasks in Spanish TASS-2017 , TASS-2016 , TASS-2015 , TASS-2014 , TASS-2013 , TASS-2012 . References UNESCO. 2003. Sharing the world of difference. UNESCO. Mohammad, Saif M. \"Ethics sheet for automatic emotion recognition and sentiment analysis.\" Computational Linguistics 48.2 (2022): 239-278. Preslav Nakov, Sara Rosenthal, Svetlana Kiritchenko, Saif M Mohammad, Zornitsa Kozareva, Alan Ritter, Veselin Stoyanov, and Xiaodan Zhu. 2016. Developing a successful SemEval task in sentiment analysis of twitter and other social media texts. Language Resources and Evaluation, 50(1):35\u201365. Mohammad, Saif, et al. \"Semeval-2018 task 1: Affect in tweets.\" Proceedings of the 12th international workshop on semantic evaluation. 2018. Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, Suresh Manandhar. 2014: SemEval-2014 Task 4: Aspect Based Sentiment Analysis, Dublin, Ireland Saif Mohammad. 2016. A Practical Guide to Sentiment Annotation: Challenges and Solutions. In Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 174\u2013179, San Diego, California. Association for Computational Linguistics. Aniruddha Ghosh, Guofu Li, Tony Veale, Paolo Rosso, Ekaterina Shutova, John Barnden, Antonio Reyes. 2015: SemEval-2015 Task 11: Sentiment Analysis of Figurative Language in Twitter, Denver, Colorado Shamsuddeen Hassan Muhammad, David Ifeoluwa Adelani, Sebastian Ruder, Ibrahim Said Ahmad, Idris Abdulmumin, Bello Shehu Bello, Monojit Choudhury, Chris Chinenye Emezue, Saheed Salahudeen Abdullahi, Anuoluwapo Aremu, Alipio Jeorge, Pavel Brazdil. 2022, NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis, Marseille, France Seid Muhie Yimam, Hizkiel Mitiku Alemayehu, Abinew Ayele, Chris Biemann. 2020: Exploring Amharic Sentiment Analysis from Social Media Texts: Building Annotation Tools and Classification Models, Barcelona, Spain (Online) Funding Acknowledgements This prize award for this shared task was generously supported by a grant from Lacuna Fund. body { text-align: justify}","title":"Home"},{"location":"#afrisenti-semeval-shared-task-12","text":"AfriSenti-SemEval: Sentiment Analysis for African Languages Part of the 17th International Workshop on Semantic Evaluation Please use the following BibTex entry to cite us if you use our dataset: SemEval-2023 Task 12: Sentiment Analysis for African Languages (AfriSenti-SemEval) . @inproceedings {muhammadSemEval2023, title = {{SemEval-2023 Task 12: Sentiment Analysis for African Languages (AfriSenti-SemEval)}}, author = {Shamsuddeen Hassan Muhammad and Idris Abdulmumin and Seid Muhie Yimam and David Ifeoluwa Adelani and Ibrahim Sa'id Ahmad and Nedjma Ousidhoum and Abinew Ali Ayele and Saif M. Mohammad and Meriem Beloucif and Sebastian Ruder}, booktitle = {Proceedings of the 17th {{International Workshop}} on {{Semantic Evaluation}} ({{SemEval-2023}})}, publisher = {{Association for Computational Linguistics}}, year = {2023}, url = {https://arxiv.org/pdf/2304.06845.pdf} } AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages . @misc {muhammad2023afrisenti, title={{AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages}}, author={Shamsuddeen Hassan Muhammad and Idris Abdulmumin and Abinew Ali Ayele and Nedjma Ousidhoum and David Ifeoluwa Adelani and Seid Muhie Yimam and Ibrahim Sa'id Ahmad and Meriem Beloucif and Saif M. Mohammad and Sebastian Ruder and Oumaima Hourrane and Pavel Brazdil and Felermino D\u00e1rio M\u00e1rio Ant\u00f3nio Ali and Davis David and Salomey Osei and Bello Shehu Bello and Falalu Ibrahim and Tajuddeen Gwadabe and Samuel Rutunda and Tadesse Belay and Wendimu Baye Messelle and Hailu Beshada Balcha and Sisay Adugna Chala and Hagos Tesfahun Gebremichael and Bernard Opoku and Steven Arthur}, year={2023}, doi={10.48550/arXiv.2302.08956}, url={https://arxiv.org/pdf/2302.08956.pdf} } Contact organizers at: afrisenti-semeval-organizers@googlegroups.com Visit CodaLab competition website AfriSenti dataset is available at task's: GitHub repo","title":"AfriSenti-SemEval Shared Task 12"},{"location":"#motivation","text":"Due to the widespread use of the Internet and social media platforms, most languages are becoming digitally available. This allows for various artificial intelligence (AI) applications that enable tasks such as sentiment analysis, machine translation and hateful content detection. According to UNESCO (2003), 30% of all living languages, around 2,058, are African languages. However, most of these languages do not have curated datasets for developing such AI applications. Recently, various individual and funded initiatives, such as the Lacuna Fund, have set out to reverse this trend and create such datasets for African languages. However, research is required to determine both the suitability of current natural language processing (NLP) techniques and the development of novel techniques to maximize the applications of such datasets. There has been a growing interest in sentiment analysis which applies to many domains, including public health, commerce/business, art and literature, social sciences, neuroscience, and psychology ( Mohammad, Saif M, 2022 ). Previous shared tasks on sentiment analysis include Mohammad, Saif M et al., (2018), Nakov et al., (2016), Pontiki et al., Ghosh et al., (2015), (2014), and so on . However, none of these tasks included African languages. Though Mohammad, Saif, et al. (2018) included standard Arabic, we focus on Arabic dialects from African countries: Algerian Arabic and Tunisian Arabizi . We believe SemEval is the right venue, due to its popularity and widespread acceptance, to carry out shared tasks for African languages to strengthen their further development. In this shared task, we have covered 17 African languages, Hausa , Yoruba , Igbo , Nigerian Pidgin from Nigeria, Amharic , Tigrinya , and Oromo from Ethiopia, Swahili from Kenya and Tanzania, Algerian Arabic dialect from Algeria, Kinyarwanda from Rwanda, Twi from Ghana, Mozambique Portuguese from Mozambique and Moroccan Arabic/Darija from Morocco.","title":"Motivation"},{"location":"#task-overview","text":"The AfriSenti-SemEval Shared Task 12 is based on a collection of Twitter datasets in 14 African languages for sentiment classification. It consists of three sub-tasks. Participants can select one or more sub-tasks depending on their preference. In each sub-task also, the participant may wish to participate in any number of languages as so wished. Task A: Monolingual Sentiment Classification Given training data in a target language, determine the polarity of a tweet in the target language (positive, negative, or neutral). If a tweet conveys both a positive and negative sentiment, whichever is the stronger sentiment should be chosen. This sub-task has 15 tracks: Note: You are free to select one or more tracks in this sub-task. Track 1: Hausa Track 2: Yoruba Track 3: Igbo Track 4: Nigerian_Pidgin Track 5: Amharic Track 6: Algerian Arabic Track 7: Moroccan Arabic/Darija, Track 8: Swahili Track 9: Kinyarwanda Track 10: Twi Track 11: Mozambican Portuguese Track 12: Xitsonga ( Mozambique Dialect ) Track 13: Setswana (data to be released soon) Track 14: isiZulu (data to be released soon) Track 15: Xitsonga (South-African Dialect, to be released soon) Note: Tweets in each language are code-mix. Read our NaijaSenti paper for more information. Task B: Multilingual Sentiment Classification Given combined training data from Task-A (Track 1 to 12), determine the polarity of a tweet in the target language (positive, negative, or neutral). This sub-task has only one track with 12 languages (Hausa, Yoruba, Igbo, Nigerian_Pidgin, Amharic, Algerian Arabic, Moroccan Arabic/Darija, Swahili, Kinyarwanda, Twi, Mozambican Portuguese, and Xitsonga( Mozambique Dialect )): Track 16: 12 languages in Task A Task C: Zero-Shot Sentiment Classification Given unlabelled tweets in two African languages (Tigrinya and Oromo), leverage any or all of the available training datasets (in Task:A ) to determine the sentiment of a tweet in the two target languages. This task has two (2) tracks. Note: You are free to select one or more tracks in this sub-task. Track 17: Zero-Shot on Tigrinya Track 18: Zero-Shot on Oromo","title":"Task Overview"},{"location":"#dataset-examples","text":"The dataset involves tweets labeled with three sentiment classes (positive, negative, neutral) in 14 African languages. Each tweet is annotated by three annotators following the annotation guidelines in ( Mohammad, Saif M, 2016 ). We use a form of majority vote to determine the sentiment of the tweet. See more in our paper ( Muhammad et al., 2022 , Yimam et al., 2020 ). Below is a sample dataset for the 4 Nigerian languges (Muhammad et al., 2022): The datasets are available via the CodaLab competition website","title":"Dataset Examples"},{"location":"#starter-kit","text":"We provide a Starter Ki t on our GitHub Repo that can be used to crearte a baseline system.","title":"Starter kit"},{"location":"#why-participate","text":"Promote NLP research involving African languages, Opportunity to write a system-description paper that describes their system, resources used, results, and analysis. Stand a chance to win an award. Opportunity to network with renowned experts in the AI and NLP community. Resources on Paper Submission Paper Submission Requirements Guidelines for Writing Papers Paper Style Files Paper Submission Site","title":"Why Participate ?"},{"location":"#important-dates","text":"Descriptions Deadlines Sample Data Ready 15 July 2022 Training Data Ready 11 September 2022 Evaluation Start 10 January 2023 Evaluation End 31 January 2023 System Description Paper Due 28th February 2023 Notification to authors 31 March 2023 Camera ready due 21 April 2023 SemEval workshop 2023 13-14 July 2023 (co-located with ACL-2023 in Toronto, Canada All deadlines are 23:59 UTC-12 (\"anywhere on Earth\").","title":"Important Dates"},{"location":"#communication","text":"Join Task Mailing List Join Task Slack Channel to communicate with the organizers. Contact Organizers: afrisenti-semeval-organizers@googlegroups.com","title":"Communication"},{"location":"#previous-shared-tasks","text":"Shared tasks in English: SemEval-2017 , SemEval-2016 , SemEval-2015 , SemEval-2014 , SemEval-2013 Shared tasks in Spanish TASS-2017 , TASS-2016 , TASS-2015 , TASS-2014 , TASS-2013 , TASS-2012 .","title":"Previous Shared Tasks"},{"location":"#references","text":"UNESCO. 2003. Sharing the world of difference. UNESCO. Mohammad, Saif M. \"Ethics sheet for automatic emotion recognition and sentiment analysis.\" Computational Linguistics 48.2 (2022): 239-278. Preslav Nakov, Sara Rosenthal, Svetlana Kiritchenko, Saif M Mohammad, Zornitsa Kozareva, Alan Ritter, Veselin Stoyanov, and Xiaodan Zhu. 2016. Developing a successful SemEval task in sentiment analysis of twitter and other social media texts. Language Resources and Evaluation, 50(1):35\u201365. Mohammad, Saif, et al. \"Semeval-2018 task 1: Affect in tweets.\" Proceedings of the 12th international workshop on semantic evaluation. 2018. Maria Pontiki, Dimitris Galanis, John Pavlopoulos, Harris Papageorgiou, Ion Androutsopoulos, Suresh Manandhar. 2014: SemEval-2014 Task 4: Aspect Based Sentiment Analysis, Dublin, Ireland Saif Mohammad. 2016. A Practical Guide to Sentiment Annotation: Challenges and Solutions. In Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages 174\u2013179, San Diego, California. Association for Computational Linguistics. Aniruddha Ghosh, Guofu Li, Tony Veale, Paolo Rosso, Ekaterina Shutova, John Barnden, Antonio Reyes. 2015: SemEval-2015 Task 11: Sentiment Analysis of Figurative Language in Twitter, Denver, Colorado Shamsuddeen Hassan Muhammad, David Ifeoluwa Adelani, Sebastian Ruder, Ibrahim Said Ahmad, Idris Abdulmumin, Bello Shehu Bello, Monojit Choudhury, Chris Chinenye Emezue, Saheed Salahudeen Abdullahi, Anuoluwapo Aremu, Alipio Jeorge, Pavel Brazdil. 2022, NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis, Marseille, France Seid Muhie Yimam, Hizkiel Mitiku Alemayehu, Abinew Ayele, Chris Biemann. 2020: Exploring Amharic Sentiment Analysis from Social Media Texts: Building Annotation Tools and Classification Models, Barcelona, Spain (Online)","title":"References"},{"location":"#funding-acknowledgements","text":"This prize award for this shared task was generously supported by a grant from Lacuna Fund. body { text-align: justify}","title":"Funding Acknowledgements"},{"location":"Resources/","text":"Resources We provide some useful information about SemEval shared task. SemEval 2023 Shared Tasks Frequently Asked Questions about SemEval Paper Submission Requirements Guidelines for Writing Papers Paper style files Paper submission site (TBD)","title":"Resources"},{"location":"Resources/#resources","text":"We provide some useful information about SemEval shared task. SemEval 2023 Shared Tasks Frequently Asked Questions about SemEval Paper Submission Requirements Guidelines for Writing Papers Paper style files Paper submission site (TBD)","title":"Resources"},{"location":"Terms/","text":"Terms and Conditions These terms and conditions are adapted from [ SemEval-2018 Task 1: Affect in Tweets ] By submitting results to this competition, you consent to the public release of your scores on this website and at the SemEval-2023 workshop and in the associated proceedings, at the task organizers' discretion. Scores may include but are not limited to, automatic and manual quantitative judgments, qualitative judgments, and such other metrics as the task organizers see fit. You accept that the ultimate decision of metric choice and score value is that of the task organizers. You further agree that the task organizers are under no obligation to release scores and that scores may be withheld if it is the task organizers' judgment that the submission was incomplete, erroneous, deceptive, or violated the letter or spirit of the competition's rules. The inclusion of a submission's scores is not an endorsement of a team or individual's submission, system, or science. A participant can be involved in exactly one team (no more). If there are reasons why it makes sense for you to be on more than one team, then email us before the evaluation period begins. In special circumstances, this may be allowed. Each team must create and use exactly one CodaLab account. The team constitution (members of a team) cannot be changed after the evaluation period has begun. During the development period: Each team can submit as many as 999 submissions. You will only be able to see the results of your submission and not others. Leaderboard is disabled You will be able to see any warnings and errors for each of your submissions. During the evaluation period: Each team can submit only 3 submissions. However, only the final submission will be considered as the official submission to the competition. You will be able to see any warnings and errors for each of your submissions. Once the competition is over, we will release the gold labels and you will be able to determine the results of various system variants you may have developed. We encourage you to report results on all of your systems (or system variants) in the system-description paper. However, we will ask you to clearly indicate the result of your official submission. We will make the final submissions of the teams public at some point after the evaluation period. The organizers and their affiliated institutions make no warranties regarding the datasets provided, including but not limited to being correct or complete. They cannot be held liable for providing access to the datasets or the usage of the datasets. Each task participant will be assigned another team\u2019s system description papers for review, using the [Open Review system](https://openreview.net). The papers will thus be peer-reviewed. The dataset should only be used for scientific or research purposes. Any other use is explicitly prohibited. The datasets must not be redistributed or shared in part or full with any third party. Redirect interested parties to this website. If you use any of the datasets provided here, cite these papers: NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis . Shamsuddeen Hassan Muhammad, David Ifeoluwa Adelani, Sebastian Ruder, Ibrahim Said Ahmad, Idris Abdulmumin, Bello Shehu Bello, Monojit Choudhury, Chris Chinenye Emezue, Saheed Salahudeen Abdullahi, Anuoluwapo Aremu, Alipio Jeorge, Pavel Brazdil. In Proceedings of the 13th Language Resources and Evaluation Conference (LREC2022) , Marseille, France, June 20-25, 2022. @InProceedings{muhammad-EtAl:2022:LREC, author = {Muhammad, Shamsuddeen Hassan and Adelani, David and Ruder, Sebastian and Ahmad, Ibrahim Sa'id and Abdulmumin, Idris and Bello, Shehu Bello and Choudhury, Monojit and Emezue, Chris Chinenye and Abdullahi, Saheed Salahuddeen and Aremu, Anuoluwapo and Jeorge, Alipio and Brazdil, Pavel}, title = {NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis}, booktitle = {Proceedings of the 13th Language Resources and Evaluation Conference}, month = {June}, year = {2022}, address = {Marseille, France}, publisher = {European Language Resources Association}, pages = {590--602}, url = {https://aclanthology.org/2022.lrec-1.63} } Exploring Amharic Sentiment Analysis from Social Media Texts: Building Annotation Tools and Classification Models . Seid Muhie Yimam, Hizkiel Mitiku Alemayehu, Abinew Ayele, Chris Biemann. In Proceedings of the 28th International Conference of Computational Linguistics (ICCL2020) , Barcelona, Spain (Online), December 2020. @inproceedings{yimam-etal-2020-exploring, title = \"Exploring {A}mharic Sentiment Analysis from Social Media Texts: Building Annotation Tools and Classification Models\", author = \"Yimam, Seid Muhie and Alemayehu, Hizkiel Mitiku and Ayele, Abinew and Biemann, Chris\", booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\", month = dec, year = \"2020\", address = \"Barcelona, Spain (Online)\", publisher = \"International Committee on Computational Linguistics\", url = \"https://aclanthology.org/2020.coling-main.91\", doi = \"10.18653/v1/2020.coling-main.91\", pages = \"1048--1060\", }","title":"Terms"},{"location":"Terms/#terms-and-conditions","text":"These terms and conditions are adapted from [ SemEval-2018 Task 1: Affect in Tweets ] By submitting results to this competition, you consent to the public release of your scores on this website and at the SemEval-2023 workshop and in the associated proceedings, at the task organizers' discretion. Scores may include but are not limited to, automatic and manual quantitative judgments, qualitative judgments, and such other metrics as the task organizers see fit. You accept that the ultimate decision of metric choice and score value is that of the task organizers. You further agree that the task organizers are under no obligation to release scores and that scores may be withheld if it is the task organizers' judgment that the submission was incomplete, erroneous, deceptive, or violated the letter or spirit of the competition's rules. The inclusion of a submission's scores is not an endorsement of a team or individual's submission, system, or science. A participant can be involved in exactly one team (no more). If there are reasons why it makes sense for you to be on more than one team, then email us before the evaluation period begins. In special circumstances, this may be allowed. Each team must create and use exactly one CodaLab account. The team constitution (members of a team) cannot be changed after the evaluation period has begun. During the development period: Each team can submit as many as 999 submissions. You will only be able to see the results of your submission and not others. Leaderboard is disabled You will be able to see any warnings and errors for each of your submissions. During the evaluation period: Each team can submit only 3 submissions. However, only the final submission will be considered as the official submission to the competition. You will be able to see any warnings and errors for each of your submissions. Once the competition is over, we will release the gold labels and you will be able to determine the results of various system variants you may have developed. We encourage you to report results on all of your systems (or system variants) in the system-description paper. However, we will ask you to clearly indicate the result of your official submission. We will make the final submissions of the teams public at some point after the evaluation period. The organizers and their affiliated institutions make no warranties regarding the datasets provided, including but not limited to being correct or complete. They cannot be held liable for providing access to the datasets or the usage of the datasets. Each task participant will be assigned another team\u2019s system description papers for review, using the [Open Review system](https://openreview.net). The papers will thus be peer-reviewed. The dataset should only be used for scientific or research purposes. Any other use is explicitly prohibited. The datasets must not be redistributed or shared in part or full with any third party. Redirect interested parties to this website. If you use any of the datasets provided here, cite these papers: NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis . Shamsuddeen Hassan Muhammad, David Ifeoluwa Adelani, Sebastian Ruder, Ibrahim Said Ahmad, Idris Abdulmumin, Bello Shehu Bello, Monojit Choudhury, Chris Chinenye Emezue, Saheed Salahudeen Abdullahi, Anuoluwapo Aremu, Alipio Jeorge, Pavel Brazdil. In Proceedings of the 13th Language Resources and Evaluation Conference (LREC2022) , Marseille, France, June 20-25, 2022. @InProceedings{muhammad-EtAl:2022:LREC, author = {Muhammad, Shamsuddeen Hassan and Adelani, David and Ruder, Sebastian and Ahmad, Ibrahim Sa'id and Abdulmumin, Idris and Bello, Shehu Bello and Choudhury, Monojit and Emezue, Chris Chinenye and Abdullahi, Saheed Salahuddeen and Aremu, Anuoluwapo and Jeorge, Alipio and Brazdil, Pavel}, title = {NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis}, booktitle = {Proceedings of the 13th Language Resources and Evaluation Conference}, month = {June}, year = {2022}, address = {Marseille, France}, publisher = {European Language Resources Association}, pages = {590--602}, url = {https://aclanthology.org/2022.lrec-1.63} } Exploring Amharic Sentiment Analysis from Social Media Texts: Building Annotation Tools and Classification Models . Seid Muhie Yimam, Hizkiel Mitiku Alemayehu, Abinew Ayele, Chris Biemann. In Proceedings of the 28th International Conference of Computational Linguistics (ICCL2020) , Barcelona, Spain (Online), December 2020. @inproceedings{yimam-etal-2020-exploring, title = \"Exploring {A}mharic Sentiment Analysis from Social Media Texts: Building Annotation Tools and Classification Models\", author = \"Yimam, Seid Muhie and Alemayehu, Hizkiel Mitiku and Ayele, Abinew and Biemann, Chris\", booktitle = \"Proceedings of the 28th International Conference on Computational Linguistics\", month = dec, year = \"2020\", address = \"Barcelona, Spain (Online)\", publisher = \"International Committee on Computational Linguistics\", url = \"https://aclanthology.org/2020.coling-main.91\", doi = \"10.18653/v1/2020.coling-main.91\", pages = \"1048--1060\", }","title":"Terms and Conditions"},{"location":"about/","text":"","title":"About"},{"location":"award/","text":"Awards Best Paper (task participants): Best Task Award TASK A: Monolingual Sentiment Classification TASK B: Sentiment Multilingual Sentiment Classification TASK C: Zero-Shot Sentiment Classification TASK D: Sentiment Classification in Multiple Languages TASK E: Sentiment Classification in Multiple Languages with Multiple Annotators","title":"Awards"},{"location":"award/#awards","text":"Best Paper (task participants): Best Task Award TASK A: Monolingual Sentiment Classification TASK B: Sentiment Multilingual Sentiment Classification TASK C: Zero-Shot Sentiment Classification TASK D: Sentiment Classification in Multiple Languages TASK E: Sentiment Classification in Multiple Languages with Multiple Annotators","title":"Awards"},{"location":"datasets/","text":"Dataset Statistics table th:first-of-type { width: 0.50%; } table th:nth-of-type(2) { width: 0.50%; } table th:nth-of-type(3) { width: 0.50%; } table th:nth-of-type(4) { width: 0.50%; } Languages Train Val Test Hausa - - - Yoruba - - - Igbo - - Nigerian-Pidgin - - Amharic - - - Algerian Arabic - - - Swahili - - Kinyarwanda - - - Mozabique Portuguess - - - Twi - - - Sestswana - - - Isuzulu - - - Tigrinya - - - table { border-collapse: collapse; } table, th, td { border: 1px solid black; } blockquote { border-left: solid blue; padding-left: 10px; }","title":"Dataset Statistics"},{"location":"datasets/#dataset-statistics","text":"table th:first-of-type { width: 0.50%; } table th:nth-of-type(2) { width: 0.50%; } table th:nth-of-type(3) { width: 0.50%; } table th:nth-of-type(4) { width: 0.50%; } Languages Train Val Test Hausa - - - Yoruba - - - Igbo - - Nigerian-Pidgin - - Amharic - - - Algerian Arabic - - - Swahili - - Kinyarwanda - - - Mozabique Portuguess - - - Twi - - - Sestswana - - - Isuzulu - - - Tigrinya - - - table { border-collapse: collapse; } table, th, td { border: 1px solid black; } blockquote { border-left: solid blue; padding-left: 10px; }","title":"Dataset Statistics"},{"location":"index33/","text":"AfriSenti-SemEval: Sentiment Analysis for African Languages Part of The 17th International Workshop on Semantic Evaluation Contact organizers: afrisenti-semeval-organizers@googlegroups.com To communicate with the organizers, join the Mailing Group: https://groups.google.com/g/afrisenti-semeval Slack Channel: AfriSenti Update (05 February): The release of official team rankings is now: on February 7th, 2023. Update (17 January): The official ranking for the shared task is Weighted F1 Evaluation starts: January 20th, 2023 Release of dev set gold labels : January 20th, 2023 Evaluation ends: January 31st, 2023 Team registration form submission deadline: February 3rd, 2023 (we will share the form soon, with more details) System Description Paper deadline: February 20, 2023 Release of official team rankings: February 5th, 2023 Release of test data gold labels: February 10th, 2023 System Description Paper deadline: February 20, 2023 Update (31 October): Xitsonga (ts) is now in Task A Multilingual (Task B) dataset has been updated to include Xitsonga Update (26 October): We released datasets for Task A: Twi - twi Task C: Xitsonga - ts We updated the final dataset for Task B - Multilingual (consisting of all released datasets for Task A) Update (15 October): We released datasets for Task A: Kinyarwanda - kr Task C: Oromo - or Task C: Tigrinya - tg Update (8 October): Due to inquiries, we included a \"How to Participate\" tab with step-by-step instructions. We provide a Starter Kit on our GitHub Repo. We released sentiment lexicons for some languages in our GitHub repo. We now have the best paper award, in addition to the best system prizes. Update (4 October): We released an updated dataset (Version 2.0). Disregard the previous version and download the current. We added Mozambican Portuguese and will soon release other languages after the annotation Motivation Due to the widespread use of the Internet and social media platforms, most languages are becoming digitally available. This allows for various artificial intelligence (AI) applications that enable tasks such as sentiment analysis, machine translation and hateful content detection. According to UNESCO (2003), 30% of all living languages, around 2,058, are African languages. However, most of these languages do not have curated datasets for developing such AI applications. Recently, various individual and funded initiatives, such as the Lacuna Fund, have set out to reverse this trend and create such datasets for African languages. However, research is required to determine both the suitability of current natural language processing (NLP) techniques and the development of novel techniques to maximize the applications of such datasets. There has been a growing interest in sentiment analysis which applies to many domains, including public health, commerce/business, art and literature, social sciences, neuroscience, and psychology ( Mohammad, Saif M, 2022 ). Previous shared tasks on sentiment analysis include Mohammad, Saif M et al., (2018), Nakov et al., (2016), Pontiki et al., Ghosh et al., (2015), (2014), and so on . However, none of these tasks included African languages. Though Mohammad, Saif, et al. (2018) included standard Arabic, we focus on Arabic dialects from African countries: Algerian Arabic and Tunisian Arabizi . We believe SemEval is the right venue, due to its popularity and widespread acceptance, to carry out shared tasks for African languages to strengthen their further development. In this shared task, we have covered 17 African languages, Hausa , Yoruba , Igbo , Nigerian Pidgin from Nigeria, Amharic , Tigrinya , and Oromo from Ethiopia, Swahili from Kenya and Tanzania, Algerian Arabic dialect from Algeria, Kinyarwanda from Rwanda, Twi from Ghana, Mozambique Portuguese from Mozambique and Moroccan Arabic/Darija from Morocco. Task Overview The AfriSenti-SemEval Shared Task 12 is based on a collection of Twitter datasets in 14 African languages for sentiment classification. It consists of three sub-tasks. Participants can select one or more sub-tasks depending on their preference. In each sub-task also, the participant may wish to participate in any number of languages as so wished. Task A: Monolingual Sentiment Classification Given training data in a target language, determine the polarity of a tweet in the target language (positive, negative, or neutral). If a tweet conveys both a positive and negative sentiment, whichever is the stronger sentiment should be chosen. This sub-task has 15 tracks: Note: You are free to select one or more tracks in this sub-task. Track 1: Hausa Track 2: Yoruba Track 3: Igbo Track 4: Nigerian_Pidgin Track 5: Amharic Track 6: Algerian Arabic Track 7: Moroccan Arabic/Darija, Track 8: Swahili Track 9: Kinyarwanda Track 10: Twi Track 11: Mozambican Portuguese Track 12: Xitsonga ( Mozambique Dialect ) Track 13: Setswana (data to be released soon) Track 14: isiZulu (data to be released soon) Track 15: Xitsonga (South-African Dialect, to be released soon) Note: Tweets in each language are code-mix. Read our NaijaSenti paper for more information. Task B: Multilingual Sentiment Classification Given combined training data from Task-A (Track 1 to 12), determine the polarity of a tweet in the target language (positive, negative, or neutral). This sub-task has only one track with 12 languages (Hausa, Yoruba, Igbo, Nigerian_Pidgin, Amharic, Algerian Arabic, Moroccan Arabic/Darija, Swahili, Kinyarwanda, Twi, Mozambican Portuguese, and Xitsonga( Mozambique Dialect )): Track 16: 12 languages in Task A Task C: Zero-Shot Sentiment Classification Given unlabelled tweets in two African languages (Tigrinya and Oromo), leverage any or all of the available training datasets (in Task:A ) to determine the sentiment of a tweet in the two target languages. This task has two (2) tracks. Note: You are free to select one or more tracks in this sub-task. Track 17: Zero-Shot on Tigrinya Track 18: Zero-Shot on Oromo Dataset Examples The dataset involves tweets labelled with three sentiment classes (positive, negative, neutral) in 14 African languages. Each tweet is annotated by three annotators following the annotation guidelines in ( Mohammad, Saif M, 2016 ). We use a form of a majority vote to determine the sentiment of the tweet. See more in our paper ( Muhammad et al., 2022 , Yimam et al., 2020 ). Below is a sample dataset for the 4 Nigerian languages (Muhammad et al., 2022): The datasets are available on the Participate tab . Starter Kit? We provide a Starter Ki t on our GitHub Repo that can be used to crearte a baseline system. Why Participate? Promote NLP research involving African languages, Opportunity to write a system-description paper that describes their system, resources used, results, and analysis. Stand a chance to win an award. Opportunity to network with renowned experts in the AI and NLP community. Resources on Paper Submission Paper Submission Requirements Guidelines for Writing Papers Paper Style Files Paper Submission Site (TBD) Previous Shared Tasks Shared tasks in English: SemEval-2017 , SemEval-2016 , SemEval-2015 , SemEval-2014 , SemEval-2013 . Shared tasks in Spanish: TASS-2017 , TASS-2016 , TASS-2015 , TASS-2014 , TASS-2013 , TASS-2012 .","title":"Index33"},{"location":"index33/#afrisenti-semeval-sentiment-analysis-for-african-languages","text":"Part of The 17th International Workshop on Semantic Evaluation Contact organizers: afrisenti-semeval-organizers@googlegroups.com To communicate with the organizers, join the Mailing Group: https://groups.google.com/g/afrisenti-semeval Slack Channel: AfriSenti Update (05 February): The release of official team rankings is now: on February 7th, 2023. Update (17 January): The official ranking for the shared task is Weighted F1 Evaluation starts: January 20th, 2023 Release of dev set gold labels : January 20th, 2023 Evaluation ends: January 31st, 2023 Team registration form submission deadline: February 3rd, 2023 (we will share the form soon, with more details) System Description Paper deadline: February 20, 2023 Release of official team rankings: February 5th, 2023 Release of test data gold labels: February 10th, 2023 System Description Paper deadline: February 20, 2023 Update (31 October): Xitsonga (ts) is now in Task A Multilingual (Task B) dataset has been updated to include Xitsonga Update (26 October): We released datasets for Task A: Twi - twi Task C: Xitsonga - ts We updated the final dataset for Task B - Multilingual (consisting of all released datasets for Task A) Update (15 October): We released datasets for Task A: Kinyarwanda - kr Task C: Oromo - or Task C: Tigrinya - tg Update (8 October): Due to inquiries, we included a \"How to Participate\" tab with step-by-step instructions. We provide a Starter Kit on our GitHub Repo. We released sentiment lexicons for some languages in our GitHub repo. We now have the best paper award, in addition to the best system prizes. Update (4 October): We released an updated dataset (Version 2.0). Disregard the previous version and download the current. We added Mozambican Portuguese and will soon release other languages after the annotation Motivation Due to the widespread use of the Internet and social media platforms, most languages are becoming digitally available. This allows for various artificial intelligence (AI) applications that enable tasks such as sentiment analysis, machine translation and hateful content detection. According to UNESCO (2003), 30% of all living languages, around 2,058, are African languages. However, most of these languages do not have curated datasets for developing such AI applications. Recently, various individual and funded initiatives, such as the Lacuna Fund, have set out to reverse this trend and create such datasets for African languages. However, research is required to determine both the suitability of current natural language processing (NLP) techniques and the development of novel techniques to maximize the applications of such datasets. There has been a growing interest in sentiment analysis which applies to many domains, including public health, commerce/business, art and literature, social sciences, neuroscience, and psychology ( Mohammad, Saif M, 2022 ). Previous shared tasks on sentiment analysis include Mohammad, Saif M et al., (2018), Nakov et al., (2016), Pontiki et al., Ghosh et al., (2015), (2014), and so on . However, none of these tasks included African languages. Though Mohammad, Saif, et al. (2018) included standard Arabic, we focus on Arabic dialects from African countries: Algerian Arabic and Tunisian Arabizi . We believe SemEval is the right venue, due to its popularity and widespread acceptance, to carry out shared tasks for African languages to strengthen their further development. In this shared task, we have covered 17 African languages, Hausa , Yoruba , Igbo , Nigerian Pidgin from Nigeria, Amharic , Tigrinya , and Oromo from Ethiopia, Swahili from Kenya and Tanzania, Algerian Arabic dialect from Algeria, Kinyarwanda from Rwanda, Twi from Ghana, Mozambique Portuguese from Mozambique and Moroccan Arabic/Darija from Morocco.","title":"AfriSenti-SemEval: Sentiment Analysis for African Languages"},{"location":"index_update/","text":"Motivation Due to the widespread use of the Internet and social media platforms, most languages are becoming digitally available. This allows for various artificial intelligence (AI) applications that enable tasks such as sentiment analysis, machine translation and hateful content detection. According to UNESCO (2003), 30% of all living languages, around 2,058, are African languages. However, most of these languages do not have curated datasets for developing such AI applications. Recently, various individual and funded initiatives, such as the Lacuna Fund, have set out to reverse this trend and create such datasets for African languages. However, research is required to determine both the suitability of current natural language processing (NLP) techniques and the development of novel techniques to maximize the applications of such datasets. <p>There has been a growing interest in sentiment analysis which applies to many domains, including public health, commerce/business, art and literature, social sciences, neuroscience, and psychology (<cite>Mohammad, Saif M, 2022</cite>). Previous shared tasks on sentiment analysis include <cite>Mohammad, Saif M et al., (2018), Nakov et al., (2016), Pontiki et al., Ghosh et al., (2015), (2014), and so on </cite> . However, none of these tasks included African languages. Though <cite> Mohammad, Saif, et al. (2018)</cite> included standard Arabic, we focus on Arabic dialects from African countries: <cite>Algerian Arabic</cite> and <cite>Tunisian Arabizi</cite>. We believe SemEval is the right venue, due to its popularity and widespread acceptance, to carry out shared tasks for African languages to strengthen their further development. </p> <p>In this shared task, we have covered 16 African languages, <a href=\"https://en.wikipedia.org/wiki/Hausa_language\">Hausa</a>, <a href=\"https://en.wikipedia.org/wiki/Yoruba_language\">Yoruba</a>, <a href=\"https://en.wikipedia.org/wiki/Igbo_language\">Igbo</a>, <a href=\"https://en.wikipedia.org/wiki/Nigerian_Pidgin\">Nigerian Pigdin</a> from Nigeria, <a href=\"https://en.wikipedia.org/wiki/Amharic, and Oromo\">Amharic</a>, <a href=\"https://en.wikipedia.org/wiki/Tigrinya_language\">Tigrinya</a> and <a href=\"https://en.wikipedia.org/wiki/Oromo_language\">Oromo</a> from Ethiopia, <a href=\"https://en.wikipedia.org/wiki/Swahili_language\">Swahili</a> from Kenya and Tanzania, <a href=\"https://en.wikipedia.org/wiki/Algerian_Arabic\">Algerian Arabic</a> dialect from Algeria, <a href=\"https://en.wikipedia.org/wiki/Kinyarwanda\">Kinyarwanda</a> from Rwanda, <a href=\"https://en.wikipedia.org/wiki/Twi\">Twi</a> from Ghana, <a href=\"https://www.google.com/search?client=safari&amp;rls=en&amp;q=Mozabique+portuguess&amp;ie=UTF-8&amp;oe=UTF-8\">Mozambique Portuguese</a> from Mozambique and <a href=\"https://en.wikipedia.org/wiki/Zulu_language\">isiZulu</a>, <a href=\"https://en.wikipedia.org/wiki/Tswana_language\">Setswana</a>, <a href=\"https://en.wikipedia.org/wiki/Tsonga_language\">Xitsonga</a> from South Africa and <a href=\"https://en.wikipedia.org/wiki/Moroccan_Arabic\">Moroccan Arabic/Darija</a> from Morocco.</p> Task Overview The AfriSenti-SemEval Shared Task 12 is based on a collection of Twitter datasets in 16 African languages for sentiment classification. It consists of three sub-tasks. Participants can select one or more tasks depending on their preference. Task A: Monolingual Sentiment Classification Given training data in a target language, determine the polarity of a tweet in the target language (positive, negative, or neutral). If a tweet For messages conveying both a positive and negative sentiment, whichever is the stronger sentiment should be chosen. This sub-task has 13 tracks: Track 1: Hausa Track 2: Yoruba Track 3: Igbo Track 4: Nigerian_Pidgin Track 5: Amharic Track 6: Algerian Arabic Track 7: Moroccan Arabic/Darija, Track 8: Swahili Track 9: Kinyarwanda ( data to be released soon ) Track 10: Twi ( data to be released soon ) Track 11: Mozambican Portuguese ( data to be released soon ) Track 12: Setswana ( data to be released soon ) Track 13: isiZulu ( data to be released soon ) Task B: Multilingual Sentiment Classification Given a combined training data from 10 African languages, determine the polarity of a tweet in the target language (positive, negative, or neutral). This sub-task has only one track (13 languages): Track 14: All languages in Task A Task C: Zero-Shot Sentiment Classification Given unlabeled tweets in three African languages (Tigrinya, Xitsonga and Oromo), leverage any or all of the available training datasets in Subtasks 1 and 2 to determine the sentiment of a tweet in the three target languages is positive, negative, or neutral. This task has three (3) tracks. This task starts on the 1st of October, 2022. Track 15: Zero-Shot on Tigrinya ( dev and test sets to be released ) Track 16: Zero-Shot on Xitsonga ( dev and test sets to be released ) Track 17: Zero-Shot on Oromo ( dev and test sets to be released ) Dataset Examples The dataset involves tweets labeled with three sentiment classes (positive, negative, neutral) in 14 African languages. Each tweet is annotated by three annotators following the annotation guidelines in ( Mohammad, Saif M, 2016 ). We use a form of majority vote to determine the sentiment of the tweet. See more in our paper ( Muhammad et al., 2022 , Yimam et al., 2020 ). Below is a sample dataset for the 4 Nigerian languges (Muhammad et al., 2022): The datasets are available on the competition website. Why Participate ? Promote NLP research involving African languages, Opportunity to write a system-description paper that describes their system, resources used, results, and analysis. Stand a chance to win award. Opportunity to network with renowned experts in the AI and NLP community. Resources on Paper Submission Paper Submission Requirements Guidelines for Writing Papers Paper Style Files Paper Submission Site (TBD) Previous Shared Tasks Shared tasks in English: SemEval-2017 , SemEval-2016 , SemEval-2015 , SemEval-2014 , SemEval-2013 Shared tasks in Spanish TASS-2017 , TASS-2016 , TASS-2015 , TASS-2014 , TASS-2013 , TASS-2012 .","title":"Index update"},{"location":"organizer/","text":"Task Organizers Below is a list of organizers for AfriSenti-SemEval Shared Task 2023 Organizers Affiliation Contact Shamsuddeen Hassan Muhammad Bayero University, Kano, Masakhane shmuhammad.csc@buk.edu.ng Seid Muhie Yimam Universit\u00e4t Hamburg, Hamburg; Masakhane seid.muhie.yimam@uni-hamburg.de Idris Abdulmumin Ahmadu Bello University Zaria, Masakhane iabdulmumin@abu.edu.ng Ibrahim Sa\u2019id Ahmad Bayero University, Kano isahmad.it@buk.edu.ng Abinew Ali Ayele Bahir Dar University, Bahir Dar abinewaliayele@gmail.com David Ifeoluwa Adelani Saarland University, MasaKhane davlanade@gmail.com Bello Shehu Bello Bayero University, Kano bsbello.cs@buk.du.ng Sebastian Ruder Google Research sebastian@ruder.io Saif M. Mohammad National Research Council, Canada uvgotsaif@gmail.com Nedjma Ousidhoum The University of Cambridge ndo24@cam.ac.uk Meriem Beloucif Uppsala University meriem.beloucif@lingfil.uu.se Task collaborators The following are collaborators for the AfriSenti. The organizers gratefully acknowledge thier support by providing datasets in their respective languages. Collaborators Affiliation Contact Salomey Osei University of Deusto, Spain & Masakane sosei@aimsammi.org Oumaima Hourrane Hassan II University of Casablanca oumaima.hourrane@gmail.com Davis David Masakhane davisdavid179@gmail.com Samuel Rutunda Digital Umuganda, Kigali, Rwanda samuel@digitalumuganda.com Felermino Ali University of Porto felerminoali@gmail.com","title":"Organizers"},{"location":"organizer/#task-organizers","text":"Below is a list of organizers for AfriSenti-SemEval Shared Task 2023 Organizers Affiliation Contact Shamsuddeen Hassan Muhammad Bayero University, Kano, Masakhane shmuhammad.csc@buk.edu.ng Seid Muhie Yimam Universit\u00e4t Hamburg, Hamburg; Masakhane seid.muhie.yimam@uni-hamburg.de Idris Abdulmumin Ahmadu Bello University Zaria, Masakhane iabdulmumin@abu.edu.ng Ibrahim Sa\u2019id Ahmad Bayero University, Kano isahmad.it@buk.edu.ng Abinew Ali Ayele Bahir Dar University, Bahir Dar abinewaliayele@gmail.com David Ifeoluwa Adelani Saarland University, MasaKhane davlanade@gmail.com Bello Shehu Bello Bayero University, Kano bsbello.cs@buk.du.ng Sebastian Ruder Google Research sebastian@ruder.io Saif M. Mohammad National Research Council, Canada uvgotsaif@gmail.com Nedjma Ousidhoum The University of Cambridge ndo24@cam.ac.uk Meriem Beloucif Uppsala University meriem.beloucif@lingfil.uu.se","title":"Task Organizers"},{"location":"organizer/#task-organizers","text":"The following are collaborators for the AfriSenti. The organizers gratefully acknowledge thier support by providing datasets in their respective languages. Collaborators Affiliation Contact Salomey Osei University of Deusto, Spain & Masakane sosei@aimsammi.org Oumaima Hourrane Hassan II University of Casablanca oumaima.hourrane@gmail.com Davis David Masakhane davisdavid179@gmail.com Samuel Rutunda Digital Umuganda, Kigali, Rwanda samuel@digitalumuganda.com Felermino Ali University of Porto felerminoali@gmail.com","title":"Task Organizers"},{"location":"participation/","text":"body { text-align: justify} How To Participate Create an account on Codalab and register for the shared task in the \u201cparticipate\u201d tab. Join the task Google group or Slack group. If you have questions, reach out to the task organizers. The organizers will respond as quickly as possible. Also, follow us on Twitter for the latest updates @AfriSenti2023. Participants can form a team (and name the team) with multiple people or a single-person team. If you are a team, you can only make submissions from the team codalab account (so, each team must use one CodaLab account). A participant can be involved in exactly one team (no more). If there are reasons why it makes sense for you to be on more than one team, then email us before the evaluation period begins. In special circumstances, this may be allowed. Update your profile, add a team name (e.g., Lion) and enter the names of team members. To do so, go to \"Competition Settings\" under Settings. For example, the user \"shmuhammad\". Read information about the task on all the competition pages (Evaluation, terms and conditions, submission format, schedule, and Prizes). Competition Phases: The competition has two phases. Development phase (Phase 1) and Test phase (Phase 2). The development phase (Phase 1): At this phase, training data (with gold label) and development data (without gold label) is released. Participants can train and evaluate their model on the train set and dev set (the dataset for this phase is released). Using any additional external data to train a model is allowed (unconstrained). However, If you are using any external data, make sure it is public data or release it immediately after the submission of your system description paper. The test phase (Phase 2): At this phase, test data (without a gold label) will be released. Participants will finally evaluate their developed model on the test data. The test data will be released on January 20 January 2023 and the evaluation ends on January 31 2023. Decide which Sub-task you want to participate in. You may choose one or all (i.e., sub-task A, sub-task B, and sub-task C). In each sub-task also, participants may wish to participate in one or more tracks. Note: To win a competition, you must participate in all tracks in a particular sub-task. Download competition data: The competition dataset contains all the data for the competition. Training, development and test (when released). To download the dataset, go to \u201cParticipate\u201d tab and click \u201cDownload Datasets\u201d as shown below. The data is also available at the competition GitHub page Before running your experiments, walk through the Google Colab Notebook to create a baseline experiment and generate the submission file (next step explain how to make a submission). Find more about the Colab Notebook via our GitHub page . Make submission of baseline experiments results (optional) Read the \"Submission format\" tab to see the submission file format. For example, to submit for Hausa language (ha), your submission file should be (pred_ha.tsv) and zipped (the name of the zipped file can be anything). Go to the \"Participate tab\", click \"Submit/View Result\" and select \"Development Task A: Hausa\". Click \"Submit button\", select the zipped file and wait a few moments for the submission to execute. Click the refresh button to check the status If the submission is successful, you will see \"Finished\". If unsuccessful, check the error log, fix the format issue (if any) and resubmit the updated zip file Click \"View detailed results\" to see your system score (Precision, Recall and Macro-F1). If you still have issues, then contact the task organizers. Make a submission on the dev set (Phase 1 or Develpement Phase This phase has already started. The procedure is similar to the previous step (submission of baseline prediction). You can make multiple submissions in this phase (as many as 999 submissions). Make a submission on the test set (Phase 2 or Evaluation phase) This phase (evaluation period) starts on 10th January, 2023. Test set without a gold label will be released. The procedure is similar to that on the dev set. These differences below apply. The leaderboard will be disabled and you will not be able to see results of your submission on the test seuntil the end of the evaluation period. You can still see if your submission was successful or resulted in some error. In case of error, you can view the error log. The number of submissions allowed per team is restricted to 3. However, only your final valid submission will be your official submission to the competition. Once the competition is over, we will release the gold labels and you will be able to determine results on various system variants you may have developed. We encourage you to report results on all of your systems (or system variants) in the system-description paper. However, we will ask you to clearly indicate the result of your official submission. We will make the final submissions of the teams public at some point after the evaluation period. After the evaluation phase, the best teams in each sub-task will win a prize. Winners are expected to share their approach in the competition to be eligible for the prize. Check \"AfriSenti Prize\" for more information. All teams that participated and submitted a result on test data are encouraged to submit a system description paper that describes their submission system. We will provide a mentorship session by Sebastian Ruder and Nedjma Djouhra on how to write a system description paper (we will announce the date). Task participants will be assigned another team\u2019s system description papers for review, using the Open Review. The papers will thus be peer-reviewed. Attend the SemEval2023 workshop (the location will be announced). If you are a student and submitted a system description paper, you can apply for the Google Conference Travel Award which provides a maximum of $3,000 in travel support. We will guide you to apply and get the grant. Walkthrough on How To Participate We prepare and record walkthrough videos explaining the competition, how to run the Colab baseline experiments and submission to Codalab. How to participate in the shared task. How to run baseline experiment using Colab we provided. How to make a submission using the result from the Colab baseline experiment. Some resources for beginners in sentiment analysis Sentiment Analysis with BERT and Transformers by HugginFace using Pytorch and Python (include Youtube videos) Tutorials on getting started with Pytorch and Torch text for sentiment analysis Sentiment Analysis on Tweets Awesome sentiment analysis Reading list for sentiment awesome sentiment analysis papers Progress in sentiment analysis (papers with code) SOTA in sentiment analysis(nlp-progress)","title":"Participation"},{"location":"prizes/","text":"AfriSenti SemEval Prizes AfriSenti-SemEval competition has a prize and will be awarded to best performing team in each of the three sub-tasks(A, B and C). We also have three leagues for the award: African League : To encourage African participation, this league is for team with at least one African. Students League : This league is dedicated Masters and Undergraduate students only.. Worldwide League : Be a participant from any country. The prize ($500) will be awarded to the best system from each league. For example, for sub-task A, three awards will be given from the three leagues. So, 9 prizes will be awarded to the total number of winners since we have 3 sub-tasks. Competition Terms and Conditions The prizes in this competition are to be distributed by the organizers of AfriSenti-SemEval 2023 (\"The Organizers\") and are guided under the following terms and regulations: How to enter Entries received after the stated closing date will not be accepted. The competition is free to enter. The Organizers will not accept responsibility for entries that are lost, mislaid, damaged or delayed in transit, regardless of cause, including, for example, as a result of any postal failure, equipment failure, technical malfunction, systems, satellite, network, server, computer hardware or software failure of any kind. By submitting an entry, you are agreeing to be bound by these Terms and Conditions. If you have any questions, please contact afrisenti-semeval-organizers@googlegroups.com The Organizers reserves the right to refuse entry, or refuse to award the prize to anyone in breach of these terms and conditions. Eligibility Only teams that submit system description paper are eligible. Unless otherwise stated, the competitions are open to all except members of the organizing team. Only one entry per team is will be considered. In entering, you confirm that you are eligible to do so and eligible to claim any prize you may win. The Organizers may require you to provide proof that you are eligible to enter the competition. The Organizers reserves all rights to disqualify you if your conduct is contrary to the spirit or intention of the prize. The competition For each sub-task, a winner will be chosen by averaging the performances of all the languages in the sub-task. For example, for sub-task-A, the winner will be chosen by averaging the performance of all the languages in the sub-task. The winner will receive prize of $500. The winner will be notified by email (using details provided at registration) within 7 days of being chosen and must provide a means to claim their prize. If a winner does not respond to The Organizers within 14 days of being notified, then the winner\u2019s prize will be forfeited and The Organizers will be entitled to select another winner in accordance with the process described above. The prize is non-exchangeable and non-transferable. The Organizers reserve the right to replace the prize with an alternative prize of equal or higher value if circumstances beyond The Organizers' control makes it necessary to do so. The decision of The Organizers regarding any aspect of the prize is final and binding and no correspondence will be entered into about it. The Organizers reserve the right to hold void, cancel, suspend, or amend the promotion where it becomes necessary to do so. Limitation of liability Insofar as is permitted by law, The Organizers or agents will not in any circumstances be responsible or liable to compensate the winner or accept any liability for any loss as a result of taking up the prize except where it is caused by the negligence of The Organizers or agents. Your statutory rights are not affected. Data protection and publicity The Organizers are committed to protecting and respecting your privacy and will only use your personal information in accordance with these Terms and Conditions. By entering, you agree that any personal information provided by you with your entry may be held and used by The Organizers or its agents to administer the competition. Governing law All our prizes in this competition will be governed by Nigerian law and entrants to the competition submit to the jurisdiction of the Nigerian courts. The Organizers reserves the right to update these Terms and Conditions from time to time and any updated version will be effective as soon as it is published on the website.","title":"Awards"},{"location":"prizes/#afrisenti-semeval-prizes","text":"AfriSenti-SemEval competition has a prize and will be awarded to best performing team in each of the three sub-tasks(A, B and C). We also have three leagues for the award: African League : To encourage African participation, this league is for team with at least one African. Students League : This league is dedicated Masters and Undergraduate students only.. Worldwide League : Be a participant from any country. The prize ($500) will be awarded to the best system from each league. For example, for sub-task A, three awards will be given from the three leagues. So, 9 prizes will be awarded to the total number of winners since we have 3 sub-tasks.","title":"AfriSenti SemEval Prizes"},{"location":"prizes/#competition-terms-and-conditions","text":"The prizes in this competition are to be distributed by the organizers of AfriSenti-SemEval 2023 (\"The Organizers\") and are guided under the following terms and regulations:","title":"Competition Terms and Conditions"},{"location":"prizes/#how-to-enter","text":"Entries received after the stated closing date will not be accepted. The competition is free to enter. The Organizers will not accept responsibility for entries that are lost, mislaid, damaged or delayed in transit, regardless of cause, including, for example, as a result of any postal failure, equipment failure, technical malfunction, systems, satellite, network, server, computer hardware or software failure of any kind. By submitting an entry, you are agreeing to be bound by these Terms and Conditions. If you have any questions, please contact afrisenti-semeval-organizers@googlegroups.com The Organizers reserves the right to refuse entry, or refuse to award the prize to anyone in breach of these terms and conditions.","title":"How to enter"},{"location":"prizes/#eligibility","text":"Only teams that submit system description paper are eligible. Unless otherwise stated, the competitions are open to all except members of the organizing team. Only one entry per team is will be considered. In entering, you confirm that you are eligible to do so and eligible to claim any prize you may win. The Organizers may require you to provide proof that you are eligible to enter the competition. The Organizers reserves all rights to disqualify you if your conduct is contrary to the spirit or intention of the prize.","title":"Eligibility"},{"location":"prizes/#the-competition","text":"For each sub-task, a winner will be chosen by averaging the performances of all the languages in the sub-task. For example, for sub-task-A, the winner will be chosen by averaging the performance of all the languages in the sub-task. The winner will receive prize of $500. The winner will be notified by email (using details provided at registration) within 7 days of being chosen and must provide a means to claim their prize. If a winner does not respond to The Organizers within 14 days of being notified, then the winner\u2019s prize will be forfeited and The Organizers will be entitled to select another winner in accordance with the process described above. The prize is non-exchangeable and non-transferable. The Organizers reserve the right to replace the prize with an alternative prize of equal or higher value if circumstances beyond The Organizers' control makes it necessary to do so. The decision of The Organizers regarding any aspect of the prize is final and binding and no correspondence will be entered into about it. The Organizers reserve the right to hold void, cancel, suspend, or amend the promotion where it becomes necessary to do so.","title":"The competition"},{"location":"prizes/#limitation-of-liability","text":"Insofar as is permitted by law, The Organizers or agents will not in any circumstances be responsible or liable to compensate the winner or accept any liability for any loss as a result of taking up the prize except where it is caused by the negligence of The Organizers or agents. Your statutory rights are not affected.","title":"Limitation of liability"},{"location":"prizes/#data-protection-and-publicity","text":"The Organizers are committed to protecting and respecting your privacy and will only use your personal information in accordance with these Terms and Conditions. By entering, you agree that any personal information provided by you with your entry may be held and used by The Organizers or its agents to administer the competition.","title":"Data protection and publicity"},{"location":"prizes/#governing-law","text":"All our prizes in this competition will be governed by Nigerian law and entrants to the competition submit to the jurisdiction of the Nigerian courts. The Organizers reserves the right to update these Terms and Conditions from time to time and any updated version will be effective as soon as it is published on the website.","title":"Governing law"},{"location":"results/","text":"System Description paper We are excited to announce that we will be hosting a workshop on writing system description papers. Participants are encouraged to submit a system description paper, regardless of their ranking. During the workshop, we will explain how to write a system description paper and participants will be able to ask questions. The session will be held on the 9th of February, 2023. The details will be sent by email to all the participants. The workshop will be delivered by Nedjma Ousidhoum and Saif Mohammad Track 1: Hausa Track 2: Yoruba Track 3: Igbo Track 4: Nigerian_Pidgin Track 5: Amharic Track 6: Algerian Arabic Track 7: Moroccan Arabic/Darija Track 8: Swahili Track 9: Kinyarwanda Track 10: Twi Track 11: Mozambican Portuguese Track 12: Xitsonga (Mozambique Dialect) Track 16: Multilingual Track 17: Zero-Shot on Tigrinya Track 18: Zero-Shot on Oromo","title":"Results"},{"location":"results/#system-description-paper","text":"We are excited to announce that we will be hosting a workshop on writing system description papers. Participants are encouraged to submit a system description paper, regardless of their ranking. During the workshop, we will explain how to write a system description paper and participants will be able to ask questions. The session will be held on the 9th of February, 2023. The details will be sent by email to all the participants. The workshop will be delivered by Nedjma Ousidhoum and Saif Mohammad","title":"System Description paper"},{"location":"results/#track-1-hausa","text":"","title":"Track 1: Hausa"},{"location":"results/#track-2-yoruba","text":"","title":"Track 2: Yoruba"},{"location":"results/#track-3-igbo","text":"","title":"Track 3: Igbo"},{"location":"results/#track-4-nigerian_pidgin","text":"","title":"Track 4: Nigerian_Pidgin"},{"location":"results/#track-5-amharic","text":"","title":"Track 5: Amharic"},{"location":"results/#track-6-algerian-arabic","text":"","title":"Track 6: Algerian Arabic"},{"location":"results/#track-7-moroccan-arabicdarija","text":"","title":"Track 7: Moroccan Arabic/Darija"},{"location":"results/#track-8-swahili","text":"","title":"Track 8: Swahili"},{"location":"results/#track-9-kinyarwanda","text":"","title":"Track 9: Kinyarwanda"},{"location":"results/#track-10-twi","text":"","title":"Track 10: Twi"},{"location":"results/#track-11-mozambican-portuguese","text":"","title":"Track 11: Mozambican Portuguese"},{"location":"results/#track-12-xitsonga-mozambique-dialect","text":"","title":"Track 12: Xitsonga (Mozambique Dialect)"},{"location":"results/#track-16-multilingual","text":"","title":"Track 16: Multilingual"},{"location":"results/#track-17-zero-shot-on-tigrinya","text":"","title":"Track 17: Zero-Shot on Tigrinya"},{"location":"results/#track-18-zero-shot-on-oromo","text":"","title":"Track 18: Zero-Shot on Oromo"}]}